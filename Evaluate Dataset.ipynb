{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code with various llms and send to WMX3 running for log and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from disk: Vectorstore/chromadb-MCCoder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task ID: 1 ðŸ”½\n",
      "codedata:\n",
      "Program begin.\n",
      "Program End.\n",
      "Elapsed_time: 3.287\n",
      "----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:  10%|â–ˆ         | 1/10 [00:15<02:17, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------\n",
      "\n",
      "Task ID: 2 ðŸ”½\n",
      "codedata:\n",
      "Program begin.\n",
      "Program End.\n",
      "Elapsed_time: 4.894\n",
      "----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:  20%|â–ˆâ–ˆ        | 2/10 [00:38<02:39, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------\n",
      "\n",
      "Task ID: 3 ðŸ”½\n",
      "codedata:\n",
      "Program begin.\n",
      "Program End.\n",
      "Elapsed_time: 3.075\n",
      "----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:54<02:08, 18.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------\n",
      "\n",
      "Task ID: 4 ðŸ”½\n",
      "codedata:\n",
      "Program begin.\n",
      "Program End.\n",
      "Elapsed_time: 3.063\n",
      "----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [01:11<01:45, 17.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------\n",
      "\n",
      "Task ID: 5 ðŸ”½\n",
      "codedata:\n",
      "Program begin.\n",
      "Program End.\n",
      "Elapsed_time: 4.301\n",
      "----------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing tasks:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [01:32<01:34, 18.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# -------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings, OpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from time import *\n",
    "\n",
    "from CodeClient import *\n",
    "from make_code_runnable import *\n",
    "from plot_log import *\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "\n",
    "# Global variable to store the name of the LLM\n",
    "llm_name = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(name=\"MCCoder and QA\", model_name=llm_name, temperature=0.2, streaming=True)\n",
    "\n",
    "# Prepare docs for RAG\n",
    "\n",
    "load_dotenv(find_dotenv()) \n",
    "\n",
    "# Preparation of documents for RAG-------------------------\n",
    "# Vectorstore, for retrieval\n",
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")   #text-embedding-3-large   #text-embedding-ada-002    #text-embedding-3-small\n",
    "\n",
    "# If pdf vectorstore exists\n",
    "vectorstore_path = \"Vectorstore/chromadb-MCCoder\"\n",
    "if os.path.exists(vectorstore_path):\n",
    "    vectorstore = Chroma(\n",
    "                    embedding_function=embedding_model,\n",
    "                    persist_directory=vectorstore_path,\n",
    "                    ) \n",
    "    print(\"load from disk: \" + vectorstore_path)\n",
    "else:\n",
    "        # Load from chunks and save to disk\n",
    "    # vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model, persist_directory=vectorstore_path) \n",
    "    print(\"load from chunks\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "\n",
    "# Txt loader of sample codes, for BM25 search\n",
    "loader = TextLoader(\"./docs/WMX3API_MCEval_Samplecodes.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "#Sample code chunk with dedicated separators\n",
    "separators = ['``']  # Adjust based on actual document structure, `` is the end of each code snippet.\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, keep_separator=True, chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "\n",
    "# Extracts and formats code instructions from a user question based on specific starting phrases.\n",
    "def coder_router(user_question):\n",
    "    \"\"\"\n",
    "    Extracts numbered sections of a user question based on specific starting phrases.\n",
    "    \n",
    "    If the question starts with 'Write a python code', 'Python code', or 'write python' (case insensitive),\n",
    "    it splits the question into paragraphs that start with numbers (e.g., 1., 2., 3.) and adds \n",
    "    'Write python code to ' after the numbers. If the question does not start \n",
    "    with the specified phrases or does not contain numbered lists, the entire question is saved into a single \n",
    "    element array. If the question does not start with the specified phrases, NoCoder is set to 1.\n",
    "    \n",
    "    Args:\n",
    "        user_question (str): The user's question.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: NoCoder (int), an array of strings with each element containing a code instruction or the entire question.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    NoCoder = 0\n",
    "    # Check if the input starts with the specified prefixes\n",
    "    if re.match(r'(?i)^(Write a python code|Python code|write python)', user_question):\n",
    "        result.append(user_question)\n",
    "    else:\n",
    "        # Save the entire question to the array and set NoCoder to 1\n",
    "        result.append(user_question)\n",
    "        NoCoder = 1\n",
    "    \n",
    "    return NoCoder, result\n",
    "\n",
    "\n",
    "\n",
    "# This function retrieves and concatenates documents for each element in the input string array.\n",
    "def coder_retrieval(coder_router_result):\n",
    "    \"\"\"\n",
    "    This function takes an array of strings as input. For each element in the array,\n",
    "    it performs a retrieval using format_docs(retriever.invoke(element))\n",
    "    and concatenates the element with the retrieval result into one long string, \n",
    "    with a newline character between them. Each concatenated result is separated by a specified separator.\n",
    "    \n",
    "    Args:\n",
    "        coder_router_result (list): An array of strings.\n",
    "\n",
    "    Returns:\n",
    "        str: A single long string formed by concatenating each element with its retrieval result,\n",
    "             separated by a newline character, and each concatenated result separated by a specified separator.\n",
    "    \"\"\"\n",
    "    separator = \"\\n----------\\n\"\n",
    "    long_string = \"\"\n",
    "    using_basic_rag = False\n",
    "    for element in coder_router_result:\n",
    "        if using_basic_rag == True:\n",
    "            # -------------------------------------------\n",
    "            # Basic retrieval\n",
    "            retrieval_result = format_docs(retriever.invoke(element))\n",
    "        else:\n",
    "            # -------------------------------------------\n",
    "            # Fusion retrieval or hybrid search\n",
    "            from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "            # initialize the bm25 retriever and faiss retriever\n",
    "            bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "            bm25_retriever.k = 5\n",
    "\n",
    "            # initialize the ensemble retriever\n",
    "            ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5])\n",
    "\n",
    "            ensemble_docs = ensemble_retriever.invoke(element)\n",
    "\n",
    "            retrieval_result = format_docs(ensemble_docs)\n",
    "\n",
    "\n",
    "        long_string += element + \"\\n\" + retrieval_result + separator\n",
    "    \n",
    "    return long_string\n",
    "\n",
    "\n",
    "# Joins the page content of each document with double newline\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Extracts code snippets written in Python from the given text\n",
    "def extract_code(text):\n",
    "    # Define the regular expression pattern to find text between ```python and ```\n",
    "    pattern = r\"```python(.*?)```\"\n",
    "\n",
    "    # Use re.findall to find all occurrences\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the matches, join them if there are multiple matches\n",
    "    return \"\\n\\n---\\n\\n\".join(matches)\n",
    "\n",
    "\n",
    "# Call LLM to generate code\n",
    "def CoderLLM(user_question, code_context):\n",
    "\n",
    "    # Prompt for code generation\n",
    "    prompt_template = \"\"\"Write a python code based on the following Question and Context. You need to choose the correct sample codes from the Context to answer the Question.\n",
    "    1. Review the Question carefully and find all the 'Axis number', IO Inputs and Outputs, and add them to the first lines of the generated code in the following format: \n",
    "    # Axes = [Axis number 1, Axis number 2, ...]\n",
    "    # Inputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    # Outputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    For instance, if the question is '...Axis 9..., ...Axis 12..., ...Axis 2..., Input 0.3 and 1.2, ...Output 3.4 and 6.1', then exact the information after matching the keywords: \"Axis\", \"Input\", \"Output\":\n",
    "    # Axes = [9, 12, 2]\n",
    "    # Inputs = [0.3, 1.2, ...]\n",
    "    # Outputs = [3.4, 6.1, ...]\n",
    "    2. Include all the generated codes within one paragraph between ```python and ``` tags. \n",
    "    3. Don't import any library.\n",
    "    4. Don't create any functions or example usage.\n",
    "    5. You need to wait until the Axes reaches the target position and stops, after the motion API, unless otherwise specified. For instance, Wmx3Lib_cm.motion.Wait(4), while 4 is the Axis specified in Axes.\n",
    "    6. Use StartPos for absolute positioning, as in 'Move Axis 4 to 200', and StartMov for relative positioning, as in 'Move Axis 4 by a distance of 200'.\n",
    "    7. Strictly follow the instruction for the specified profile type.\n",
    "    8. If acceleration/acc, deceleration/dec, and velocity/speed are not specified in the user query, use the default values provided in the context's sample codes.\n",
    "    ----------------------------------------------\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "\n",
    "    Context: \n",
    "    {context}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    prompt_code = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    rag_chain = (\n",
    "        #{\"context\": context_msg, \"question\": RunnablePassthrough()}\n",
    "        prompt_code\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    " \n",
    "    codes = rag_chain.invoke({\"context\": code_context, \"question\": user_question})\n",
    "    \n",
    "    # Get python code from the output of LLM\n",
    "    codes = extract_code(codes)\n",
    "\n",
    "    return codes\n",
    "\n",
    "\n",
    "# Corrects the provided error codes based on specified error information calling LLM\n",
    "def self_correct(err_codes):\n",
    "   # remember to write \"python\" code in the prompt later\n",
    "    template = \"\"\"Correct the following codes based on the error infomation. \n",
    "    1. If the error is 'variable_name is not defined', try assigning it a value of None firstly.\n",
    "    2. If an error message indicates that acc, dec, velocity, or other arguments are out of range, assign them the default values presented in the preceding code samples.\n",
    "\n",
    "        {err_codes}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    code_corrected=rag_chain.invoke({\"err_codes\": err_codes})\n",
    " \n",
    "    return(code_corrected)\n",
    "\n",
    "\n",
    "# Decompose tasks from user questions using a LLM\n",
    "def task_decomposer_llm(user_question):\n",
    "   #  \n",
    "    template = \"\"\"Decompose the tasks based on the question, if it contains a numbered list. For example, the question 'Write Python code to execute the following tasks: 1. Move Axis 1 to 200; 2. Move Axis 9 a distance of 150; 3. Set IO output 4.3 to 1, and sleep for 1.5 seconds.' will be decomposed into three tasks as output adding 'Write python code to ':\n",
    "    1. Write python code to Move Axis 1 to 200;\n",
    "    2. Write python code to Move Axis 9 a distance of 150;\n",
    "    3. Write python code to Set IO output 4.3 to 1, and sleep for 1.5 seconds.\n",
    "\n",
    "    If there are not multiple tasks, just output the original question.\n",
    "        {questions}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    task_str=rag_chain.invoke({\"questions\": user_question})\n",
    "    pattern = re.compile(r'\\d+\\.\\s')\n",
    "    # Find all positions of task numbers\n",
    "    positions = [match.start() for match in pattern.finditer(task_str)]\n",
    "    tasks = []\n",
    "\n",
    "    # Loop through the positions to extract tasks\n",
    "    for i in range(len(positions)):\n",
    "        start = positions[i]\n",
    "        end = positions[i + 1] if i + 1 < len(positions) else len(task_str)\n",
    "        task = task_str[start:end].strip()\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # If there are no multiple tasks, just output the original question.\n",
    "    if len(positions) == 0:\n",
    "        tasks.append(task_str)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Decompose tasks from user questions using a LLM\n",
    "def tasks_composer_llm(user_question, code_from_llm_str):\n",
    "   #  \n",
    "    template = \"\"\"Write a Python code that incorporates the Context_Codes (tasks) to address the following Question:\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "\n",
    "    Context_Codes: \n",
    "    {context}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    code_from_composer_llm=rag_chain.invoke({\"questions\": user_question, \"context\": code_from_llm_str})\n",
    "    # Get python code from the output of LLM\n",
    "    code_from_composer_llm = extract_code(code_from_composer_llm)\n",
    "    \n",
    "    return code_from_composer_llm\n",
    "\n",
    "\n",
    "# Send the code generated by the LLM to WMX3 engine\n",
    "def RunCode(codes_from_llm, task_info):\n",
    "\n",
    "    RunnableCode = make_code_runnable(codes_from_llm, llm_name, task_info)\n",
    "    # print(RunnableCode)\n",
    "\n",
    "    # Run Code in WMX3\n",
    "    codereturn = SendCode(RunnableCode)\n",
    "    # If there is an error, invoke llm to self-correct, and then send to WMX3 again.\n",
    "    if 'error' in codereturn.lower():\n",
    "        err_codes_0 = codereturn + '\\n # ------------------------------- \\n' + codes_from_llm\n",
    "        code_corrected = self_correct(err_codes_0)\n",
    "        msgCode = extract_code(code_corrected)\n",
    "        RunnableCode = make_code_runnable(msgCode, llm_name, task_info)\n",
    "        codereturn = SendCode(RunnableCode)\n",
    "        if 'error' in codereturn.lower():\n",
    "            self_correct_str = \"Self-correction but still got an error.\\n\\n\"\n",
    "        else:\n",
    "            self_correct_str = \"Self-corrected.\\n\\n\"\n",
    "        \n",
    "        codereturn += self_correct_str\n",
    "        print(self_correct_str)\n",
    "\n",
    "\n",
    "    return codereturn\n",
    "    \n",
    "\n",
    "\n",
    "# Evaluate dataset\n",
    "def EvalDataset():\n",
    "    # Define task range\n",
    "    task_infos = range(1, 11)\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(\"./docs/WMX3API_MCEval_Evaluation_Dataset.json\", \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    # Initialize statistics dictionary\n",
    "    statistics = {\n",
    "        1: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        2: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        3: {'correct': 0, 'syntax_error': 0, 'other_error': 0}\n",
    "    }\n",
    "\n",
    "    total_correct = 0\n",
    "    total_syntax_error = 0\n",
    "    total_other_error = 0\n",
    "    total_self_corrected_error = 0\n",
    "\n",
    "    # Initialize error log list\n",
    "    error_log = []\n",
    "    self_corrected_log = []\n",
    "\n",
    "    # Iterate through task range\n",
    "    for task_info in tqdm(task_infos, desc=\"Processing tasks\"):\n",
    "        # Get task information\n",
    "        task_entry = next(item for item in dataset if item[\"TaskId\"] == task_info)\n",
    "        user_question = task_entry[\"Instruction\"]\n",
    "        difficulty = task_entry[\"Difficulty\"]\n",
    "        task_id = task_entry[\"TaskId\"]\n",
    "\n",
    "        # Call coder_router function\n",
    "        NoCoder, coder_router_result = coder_router(user_question)\n",
    "\n",
    "        # Route the result based on NoCoder value\n",
    "        if NoCoder == 0: # Coding task\n",
    "            tasks = task_decomposer_llm(user_question)\n",
    "            # Initialize a code string from LLM\n",
    "            code_from_llm_str = ''\n",
    "            for i in range(len(tasks)):\n",
    "                coder_return = coder_retrieval(coder_router_result)  # Code context\n",
    "                # Call CoderLLM function\n",
    "                code_from_llm = CoderLLM(user_question, coder_return)\n",
    "                code_from_llm_str += f'\\n#---------task{i}:---------\\n' + tasks[i] + f'\\n#---------code{i}:---------\\n' + code_from_llm \n",
    "\n",
    "        print(f\"Task ID: {task_id} ðŸ”½\")\n",
    "        # Single task\n",
    "        if len(tasks) == 1:\n",
    "            # Run code\n",
    "            CoderResult = RunCode(code_from_llm, task_info)\n",
    "        else:  # Multi tasks\n",
    "            code_from_composer_llm = tasks_composer_llm(user_question, code_from_llm_str)\n",
    "            CoderResult = RunCode(code_from_composer_llm, task_info)\n",
    "\n",
    "        # Init Correctness, if equals 1, then plot.\n",
    "        Correctness = 0\n",
    "        # Check for \"Self-corrected\" in the result\n",
    "        if 'self-corrected' in CoderResult.lower():\n",
    "            self_corrected_log.append({'TaskId': task_info, 'Result': CoderResult})\n",
    "            if 'error' in CoderResult.lower():\n",
    "                error_info = {\n",
    "                    'TaskId': task_info,\n",
    "                    'Error': CoderResult\n",
    "                }\n",
    "                error_log.append(error_info)\n",
    "                \n",
    "                total_self_corrected_error += 1\n",
    "                if any(error in CoderResult.lower() for error in ('syntax error', 'NameError', 'AttributeError')):\n",
    "                    statistics[difficulty]['syntax_error'] += 1\n",
    "                    total_syntax_error += 1\n",
    "                else:\n",
    "                    statistics[difficulty]['other_error'] += 1\n",
    "                    total_other_error += 1\n",
    "            else:\n",
    "                statistics[difficulty]['correct'] += 1\n",
    "                total_correct += 1\n",
    "                Correctness = 1\n",
    "        else:\n",
    "            # Check if there is an error in the result\n",
    "            if 'error' in CoderResult.lower():\n",
    "                error_info = {\n",
    "                    'TaskId': task_info,\n",
    "                    'Error': CoderResult\n",
    "                }\n",
    "                error_log.append(error_info)\n",
    "\n",
    "                if any(error in CoderResult.lower() for error in ('syntax error', 'NameError', 'AttributeError')):\n",
    "                    statistics[difficulty]['syntax_error'] += 1\n",
    "                    total_syntax_error += 1\n",
    "                else:\n",
    "                    statistics[difficulty]['other_error'] += 1\n",
    "                    total_other_error += 1\n",
    "            else:\n",
    "                statistics[difficulty]['correct'] += 1\n",
    "                total_correct += 1\n",
    "                Correctness = 1\n",
    "\n",
    "        if Correctness == 1:\n",
    "            folder_path = f'/Users/yin/Documents/GitHub/MCCodeLog/{llm_name}'\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            # Plot with the log file\n",
    "            log_file_path = os.path.join(folder_path, f\"{task_info}_{llm_name}_log.txt\")\n",
    "            plot_log(log_file_path)\n",
    "            print('# -------------------------------------------------------------------------\\n')\n",
    "\n",
    "    # Print overall statistics\n",
    "    total_tasks = total_correct + total_syntax_error + total_other_error\n",
    "    print(\"Overall Results:\")\n",
    "    print(f\"  Total Correct: {total_correct} ({total_correct / total_tasks:.2%})\")\n",
    "    print(f\"  Total Syntax Error: {total_syntax_error} ({total_syntax_error / total_tasks:.2%})\")\n",
    "    print(f\"  Total Other Error: {total_other_error} ({total_other_error / total_tasks:.2%})\")\n",
    "    print(f\"  Total Self-corrected Errors: {total_self_corrected_error}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Print statistics by difficulty\n",
    "    for difficulty, counts in statistics.items():\n",
    "        total_difficulty = counts['correct'] + counts['syntax_error'] + counts['other_error']\n",
    "        if total_difficulty != 0:\n",
    "            print(f\"Difficulty: {difficulty}\")\n",
    "            print(f\"  Correct: {counts['correct']} ({counts['correct'] / total_difficulty:.2%})\")\n",
    "            print(f\"  Syntax Error: {counts['syntax_error']} ({counts['syntax_error'] / total_difficulty:.2%})\")\n",
    "            print(f\"  Other Error: {counts['other_error']} ({counts['other_error'] / total_difficulty:.2%})\")\n",
    "            print(\"\")\n",
    "\n",
    "    # Print error log\n",
    "    if error_log:\n",
    "        print(\"Error Log:\")\n",
    "        for error in error_log:\n",
    "            print(f\"  TaskId: {error['TaskId']}, Error: {error['Error']}\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Print self-corrected log\n",
    "    if self_corrected_log:\n",
    "        print(\"Self-corrected Log:\")\n",
    "        for log in self_corrected_log:\n",
    "            print(f\"  TaskId: {log['TaskId']}, Result: {log['Result']}\")\n",
    "        print(\"\")\n",
    "\n",
    "EvalDataset()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-IMu3vKF7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
