{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Dataset in turn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code with llm and run with log and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_dotenv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 136\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# LLM's name to test\u001b[39;00m\n\u001b[1;32m    135\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 136\u001b[0m DocsforRAG()\n",
      "Cell \u001b[0;32mIn[1], line 30\u001b[0m, in \u001b[0;36mDocsforRAG\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDocsforRAG\u001b[39m():\n\u001b[0;32m---> 30\u001b[0m     load_dotenv(find_dotenv()) \n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Preparation of documents for RAG-------------------------\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Vectorstore, for retrieval\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     embedding_model\u001b[38;5;241m=\u001b[39mOpenAIEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-embedding-3-large\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \u001b[38;5;66;03m#text-embedding-3-large   #text-embedding-ada-002    #text-embedding-3-small\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dotenv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings, OpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from time import *\n",
    "\n",
    "from CodeClient import *\n",
    "from make_code_runnable import *\n",
    "from plot_log import *\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "\n",
    "# Global variable to store the name of the LLM\n",
    "llm_name = \"gpt-4o\"\n",
    "llm = ChatOpenAI(name=\"MCCoder and QA\", model_name=llm_name, temperature=0.2, streaming=True)\n",
    "\n",
    "# Prepare docs for RAG\n",
    "\n",
    "load_dotenv(find_dotenv()) \n",
    "\n",
    "# Preparation of documents for RAG-------------------------\n",
    "# Vectorstore, for retrieval\n",
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")   #text-embedding-3-large   #text-embedding-ada-002    #text-embedding-3-small\n",
    "\n",
    "# If pdf vectorstore exists\n",
    "vectorstore_path = \"Vectorstore/chromadb-MCCoder\"\n",
    "if os.path.exists(vectorstore_path):\n",
    "    vectorstore = Chroma(\n",
    "                    embedding_function=embedding_model,\n",
    "                    persist_directory=vectorstore_path,\n",
    "                    ) \n",
    "    print(\"load from disk: \" + vectorstore_path)\n",
    "else:\n",
    "        # Load from chunks and save to disk\n",
    "    # vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model, persist_directory=vectorstore_path) \n",
    "    print(\"load from chunks\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})\n",
    "\n",
    "# Txt loader of sample codes, for BM25 search\n",
    "loader = TextLoader(\"./docs/WMX3API_MCEval_Samplecodes.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "#Sample code chunk with dedicated separators\n",
    "separators = ['``']  # Adjust based on actual document structure, `` is the end of each code snippet.\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, keep_separator=True, chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "\n",
    "# Extracts and formats code instructions from a user question based on specific starting phrases.\n",
    "async def coder_router(user_question):\n",
    "    \"\"\"\n",
    "    Extracts numbered sections of a user question based on specific starting phrases.\n",
    "    \n",
    "    If the question starts with 'Write a python code', 'Python code', or 'write python' (case insensitive),\n",
    "    it splits the question into paragraphs that start with numbers (e.g., 1., 2., 3.) and adds \n",
    "    'Write python code to ' after the numbers. If the question does not start \n",
    "    with the specified phrases or does not contain numbered lists, the entire question is saved into a single \n",
    "    element array. If the question does not start with the specified phrases, NoCoder is set to 1.\n",
    "    \n",
    "    Args:\n",
    "        user_question (str): The user's question.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: NoCoder (int), an array of strings with each element containing a code instruction or the entire question.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    NoCoder = 0\n",
    "    # Check if the input starts with the specified prefixes\n",
    "    if re.match(r'(?i)^(Write a python code|Python code|write python)', user_question):\n",
    "        result.append(user_question)\n",
    "    else:\n",
    "        # Save the entire question to the array and set NoCoder to 1\n",
    "        result.append(user_question)\n",
    "        NoCoder = 1\n",
    "    \n",
    "    return NoCoder, result\n",
    "\n",
    "\n",
    "\n",
    "# This function retrieves and concatenates documents for each element in the input string array.\n",
    "async def coder_retrieval(coder_router_result):\n",
    "    \"\"\"\n",
    "    This function takes an array of strings as input. For each element in the array,\n",
    "    it performs a retrieval using format_docs(retriever.invoke(element))\n",
    "    and concatenates the element with the retrieval result into one long string, \n",
    "    with a newline character between them. Each concatenated result is separated by a specified separator.\n",
    "    \n",
    "    Args:\n",
    "        coder_router_result (list): An array of strings.\n",
    "\n",
    "    Returns:\n",
    "        str: A single long string formed by concatenating each element with its retrieval result,\n",
    "             separated by a newline character, and each concatenated result separated by a specified separator.\n",
    "    \"\"\"\n",
    "    separator = \"\\n----------\\n\"\n",
    "    long_string = \"\"\n",
    "    for element in coder_router_result:\n",
    "\n",
    "        # Fusion retrieval or hybrid search\n",
    "        from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "        # initialize the bm25 retriever and faiss retriever\n",
    "        bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "        bm25_retriever.k = 5\n",
    "\n",
    "        # initialize the ensemble retriever\n",
    "        ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5])\n",
    "\n",
    "        ensemble_docs = ensemble_retriever.get_relevant_documents(element)\n",
    "\n",
    "        retrieval_result = format_docs(ensemble_docs)\n",
    "        long_string += element + \"\\n\" + retrieval_result + separator\n",
    "    \n",
    "    return long_string\n",
    "\n",
    "\n",
    "# Joins the page content of each document with double newline\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Extracts code snippets written in Python from the given text\n",
    "def extract_code(text):\n",
    "    # Define the regular expression pattern to find text between ```python and ```\n",
    "    pattern = r\"```python(.*?)```\"\n",
    "\n",
    "    # Use re.findall to find all occurrences\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the matches, join them if there are multiple matches\n",
    "    return \"\\n\\n---\\n\\n\".join(matches)\n",
    "\n",
    "\n",
    "# Call LLM to generate code\n",
    "def CallLLM(eval_question):\n",
    "\n",
    "    # Input text\n",
    "    user_question = eval_question\n",
    "    \n",
    "    # Call coder_router function\n",
    "    NoCoder, coder_router_result = coder_router(user_question)\n",
    "\n",
    "    # Route the result based on NoCoder value\n",
    "    if NoCoder == 0:\n",
    "        coder_return = coder_retrieval(coder_router_result)\n",
    "        context_msg = coder_return\n",
    "\n",
    "    question = user_question\n",
    "    context = context_msg\n",
    "\n",
    "    # Prompt for code generation\n",
    "    prompt_template = \"\"\"Write a python code based on the following Question and Context. You need to choose the correct codes from the Context to answer the Question.\n",
    "    1. Review the question carefully and find all the 'Axis number', IO Inputs and Outputs, and add them to the first lines of the generated code in the following format: \n",
    "    # Axes = [Axis number 1, Axis number 2, ...]\n",
    "    # Inputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    # Outputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    For instance, if the question is '...Axis 9..., ...Axis 12..., ...Axis 2..., Input 0.3 and 1.2, ...Output 3.4 and 6.1', then \n",
    "    # Axes = [9, 12, 2]\n",
    "    # Inputs = [0.3, 1.2, ...]\n",
    "    # Outputs = [3.4, 6.1, ...]\n",
    "    2. Include all the generated codes within one paragraph between ```python and ``` tags. \n",
    "    3. Don't import any library.\n",
    "    4. Don't create any functions or example usage.\n",
    "    5. You need to wait until the axis reaches the target position and stops, unless otherwise specified.\n",
    "    ----------------------------------------------\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "\n",
    "    Context: \n",
    "    {context}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    prompt_code = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    runnable = (\n",
    "        # {\"context\": context_msg, \"question\": user_question},\n",
    "         prompt_code\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    codes = runnable.invoke(user_question)\n",
    "\n",
    "    return codes\n",
    "\n",
    "\n",
    "def RunCode(codes_from_llm, task_info):\n",
    "\n",
    "    # Get python code from the output of LLM\n",
    "    msgCode = extract_code(codes_from_llm)\n",
    "    RunnableCode = make_code_runnable(msgCode, llm_name, task_info)\n",
    "    # print(RunnableCode)\n",
    "\n",
    "    # Run Code in WMX3\n",
    "    codereturn = SendCode(RunnableCode)\n",
    "    # if 'error' in codereturn:\n",
    "    #     err_codes_0 = codereturn + '\\n # ------------------------------- \\n' + RunnableCode\n",
    "    #     code_corrected = await self_correct(err_codes_0)\n",
    "    return codereturn\n",
    "    \n",
    "\n",
    "\n",
    "def EvalDataset():\n",
    " \n",
    "    # Define task range\n",
    "    task_infos = range(1, 4)\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(\"./docs/WMX3API_MCEval_Evaluation_Dataset.json\", \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    # Initialize statistics dictionary\n",
    "    statistics = {\n",
    "        1: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        2: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        3: {'correct': 0, 'syntax_error': 0, 'other_error': 0}\n",
    "    }\n",
    "\n",
    "    total_correct = 0\n",
    "    total_syntax_error = 0\n",
    "    total_other_error = 0\n",
    "\n",
    "    # Iterate through task range\n",
    "    for task_info in tqdm(task_infos, desc=\"Processing tasks\"):\n",
    "        # Get task information\n",
    "        task_entry = next(item for item in dataset if item[\"TaskId\"] == task_info)\n",
    "        user_question = task_entry[\"Instruction\"]\n",
    "        difficulty = task_entry[\"Difficulty\"]\n",
    "\n",
    "        # Call LLM function\n",
    "        codes_from_llm = CallLLM(user_question)\n",
    "\n",
    "        # Run code\n",
    "        CodeResult = RunCode(codes_from_llm, task_info)\n",
    "\n",
    "        # Check if there is an error in the result\n",
    "        if 'error' in CodeResult:\n",
    "            if 'syntax error' in CodeResult['error']:\n",
    "                statistics[difficulty]['syntax_error'] += 1\n",
    "                total_syntax_error += 1\n",
    "            else:\n",
    "                statistics[difficulty]['other_error'] += 1\n",
    "                total_other_error += 1\n",
    "        else:\n",
    "            statistics[difficulty]['correct'] += 1\n",
    "            total_correct += 1\n",
    "            # Plot with the log file\n",
    "            log_file_path = os.path.join(folder_path, f\"{task_info}_{llm_name}_log.txt\")\n",
    "            plot_log(log_file_path)\n",
    "            print('# -------------------------------------------------------------------------\\n')\n",
    "\n",
    "    # Print overall statistics\n",
    "    total_tasks = total_correct + total_syntax_error + total_other_error\n",
    "    print(\"Overall Results:\")\n",
    "    print(f\"  Total Correct: {total_correct} ({total_correct / total_tasks:.2%})\")\n",
    "    print(f\"  Total Syntax Error: {total_syntax_error} ({total_syntax_error / total_tasks:.2%})\")\n",
    "    print(f\"  Total Other Error: {total_other_error} ({total_other_error / total_tasks:.2%})\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Print statistics by difficulty\n",
    "    for difficulty, counts in statistics.items():\n",
    "        total_difficulty = counts['correct'] + counts['syntax_error'] + counts['other_error']\n",
    "        print(f\"Difficulty: {difficulty}\")\n",
    "        print(f\"  Correct: {counts['correct']} ({counts['correct'] / total_difficulty:.2%})\")\n",
    "        print(f\"  Syntax Error: {counts['syntax_error']} ({counts['syntax_error'] / total_difficulty:.2%})\")\n",
    "        print(f\"  Other Error: {counts['other_error']} ({counts['other_error'] / total_difficulty:.2%})\")\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# EvalDataset()\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-IMu3vKF7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
