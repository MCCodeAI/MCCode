{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate code with various llms and send to WMX3 running for log and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load from disk: Vectorstore/chromadb-MCCoder\n",
      "error string:----------------------\n",
      "AttributeError: 'Io' object has no attribute 'GetInputBit'. Did you mean: 'GetInBit'?\n",
      "[Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 719850}, page_content='{\\n        \"No\": 660,\\n        \"FunctionC++\": \"WMX3APIFUNC GetInBitEx(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetInBitEx(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data. \\\\n\",\\n        \"Remarks\": \"This function has a faster response time compared to GetInBit.\\\\n\\\\nBecause of the difference in the data flow channel, this function cannot be called from an ApiBuffer.\\\\n\\\\nThis function obtains the input data that was read by the engine during the most recent interrupt (communication cycle). \\\\n\",\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an input bit. \"\\n    },'), Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 694227}, page_content='{\\n        \"No\": 628,\\n        \"FunctionC++\": \"WMX3APIFUNC GetInBit(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetInBit(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data. \\\\n\",\\n        \"Remarks\": \"This function obtains the input data that was read by the engine during the most recent interrupt (communication cycle). \",\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an input bit.\"\\n    },'), Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 702629}, page_content='{\\n        \"No\": 637,\\n        \"FunctionC++\": \"WMX3APIFUNC GetOutBit(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetOutBit(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data.  \\\\n\",\\n        \"Remarks\": NaN,\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an output bit.\"\\n    },')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 719850}, page_content='{\\n        \"No\": 660,\\n        \"FunctionC++\": \"WMX3APIFUNC GetInBitEx(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetInBitEx(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data. \\\\n\",\\n        \"Remarks\": \"This function has a faster response time compared to GetInBit.\\\\n\\\\nBecause of the difference in the data flow channel, this function cannot be called from an ApiBuffer.\\\\n\\\\nThis function obtains the input data that was read by the engine during the most recent interrupt (communication cycle). \\\\n\",\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an input bit. \"\\n    },'),\n",
       " Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 694227}, page_content='{\\n        \"No\": 628,\\n        \"FunctionC++\": \"WMX3APIFUNC GetInBit(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetInBit(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data. \\\\n\",\\n        \"Remarks\": \"This function obtains the input data that was read by the engine during the most recent interrupt (communication cycle). \",\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an input bit.\"\\n    },'),\n",
       " Document(metadata={'source': './docs/WMX3API_FunctionPython.json', 'start_index': 702629}, page_content='{\\n        \"No\": 637,\\n        \"FunctionC++\": \"WMX3APIFUNC GetOutBit(int addr, int bit, unsigned char *pData)\",\\n        \"FunctionPython\": \"def GetOutBit(addr, bit)\",\\n        \"Parameters\": \"[in] addr The byte address of the bit to get. \\\\n[in] bit The bit address of the bit to get. \\\\n[out] pData A pointer to a unsigned char that will receive the data.  \\\\n\",\\n        \"Remarks\": NaN,\\n        \"ReturnType\": \"tuple\",\\n        \"ReturnValue\": \"0 : int - error code\",\\n        \"Class\": \"Io Class\",\\n        \"Instruction\": \"Get the value of an output bit.\"\\n    },')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain.schema.runnable.config import RunnableConfig\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader, TextLoader, PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings, OpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "from time import *\n",
    "\n",
    "from CodeClient import *\n",
    "from make_code_runnable import *\n",
    "from plot_log import *\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "\n",
    "# Global variable to store the name of the LLM\n",
    "llm_name = \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(name=\"MCCoder and QA\", model_name=llm_name, temperature=0.2, streaming=True)\n",
    "\n",
    "# Prepare docs for RAG\n",
    "\n",
    "load_dotenv(find_dotenv()) \n",
    "\n",
    "# Preparation of documents for RAG-------------------------\n",
    "# Vectorstore, for retrieval\n",
    "embedding_model=OpenAIEmbeddings(model=\"text-embedding-3-large\")   #text-embedding-3-large   #text-embedding-ada-002    #text-embedding-3-small\n",
    "\n",
    "# If pdf vectorstore exists\n",
    "vectorstore_path = \"Vectorstore/chromadb-MCCoder\"\n",
    "if os.path.exists(vectorstore_path):\n",
    "    vectorstore = Chroma(\n",
    "                    embedding_function=embedding_model,\n",
    "                    persist_directory=vectorstore_path,\n",
    "                    ) \n",
    "    print(\"load from disk: \" + vectorstore_path)\n",
    "else:\n",
    "        # Load from chunks and save to disk\n",
    "    # vectorstore = Chroma.from_documents(documents=splits, embedding=embedding_model, persist_directory=vectorstore_path) \n",
    "    print(\"load from chunks\")\n",
    "\n",
    "\n",
    "\n",
    "# Txt loader of sample codes, for BM25 search\n",
    "loader = TextLoader(\"./docs/WMX3API_MCEval_Samplecodes.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "#Sample code chunk with dedicated separators\n",
    "separators = ['``']  # Adjust based on actual document structure, `` is the end of each code snippet.\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, keep_separator=True, chunk_size=1000, chunk_overlap=200, add_start_index=True)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Extracts and formats code instructions from a user question based on specific starting phrases.\n",
    "def coder_router(user_question):\n",
    "    \"\"\"\n",
    "    Extracts numbered sections of a user question based on specific starting phrases.\n",
    "    \n",
    "    If the question starts with 'Write a python code', 'Python code', or 'write python' (case insensitive),\n",
    "    it splits the question into paragraphs that start with numbers (e.g., 1., 2., 3.) and adds \n",
    "    'Write python code to ' after the numbers. If the question does not start \n",
    "    with the specified phrases or does not contain numbered lists, the entire question is saved into a single \n",
    "    element array. If the question does not start with the specified phrases, NoCoder is set to 1.\n",
    "    \n",
    "    Args:\n",
    "        user_question (str): The user's question.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: NoCoder (int), an array of strings with each element containing a code instruction or the entire question.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    NoCoder = 0\n",
    "    # Check if the input starts with the specified prefixes\n",
    "    if re.match(r'(?i)^(Write a python code|Python code|write python)', user_question):\n",
    "        result.append(user_question)\n",
    "    else:\n",
    "        # Save the entire question to the array and set NoCoder to 1\n",
    "        result.append(user_question)\n",
    "        NoCoder = 1\n",
    "    \n",
    "    return NoCoder, result\n",
    "\n",
    "\n",
    "\n",
    "# This function retrieves and concatenates documents for each element in the input string array.\n",
    "def coder_retrieval(coder_router_result):\n",
    "    \"\"\"\n",
    "    This function takes an array of strings as input. For each element in the array,\n",
    "    it performs a retrieval using format_docs(retriever.invoke(element))\n",
    "    and concatenates the element with the retrieval result into one long string, \n",
    "    with a newline character between them. Each concatenated result is separated by a specified separator.\n",
    "    \n",
    "    Args:\n",
    "        coder_router_result (list): An array of strings.\n",
    "\n",
    "    Returns:\n",
    "        str: A single long string formed by concatenating each element with its retrieval result,\n",
    "             separated by a newline character, and each concatenated result separated by a specified separator.\n",
    "    \"\"\"\n",
    "    separator = \"\\n----------\\n\"\n",
    "    long_string = \"\"\n",
    "    using_basic_rag = False\n",
    "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 10})\n",
    "    for element in coder_router_result:\n",
    "        if using_basic_rag == True:\n",
    "            # -------------------------------------------\n",
    "            # Basic retrieval\n",
    "            retrieval_result = format_docs(retriever.invoke(element))\n",
    "        else:\n",
    "            # -------------------------------------------\n",
    "            # Fusion retrieval or hybrid search\n",
    "\n",
    "\n",
    "            # initialize the bm25 retriever  \n",
    "            bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "            bm25_retriever.k = 5\n",
    "\n",
    "            # initialize the ensemble retriever\n",
    "            ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, retriever], weights=[0.5, 0.5])\n",
    "\n",
    "            ensemble_docs = ensemble_retriever.invoke(element)\n",
    "\n",
    "            retrieval_result = format_docs(ensemble_docs)\n",
    "\n",
    "\n",
    "        long_string += element + \"\\n\" + retrieval_result + separator\n",
    "    \n",
    "    return long_string\n",
    "\n",
    "\n",
    "# Joins the page content of each document with double newline\n",
    "def format_docs(docs):\n",
    "   return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Extracts code snippets written in Python from the given text\n",
    "def extract_code(text):\n",
    "    # Define the regular expression pattern to find text between ```python and ```\n",
    "    pattern = r\"```python(.*?)```\"\n",
    "\n",
    "    # Use re.findall to find all occurrences\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "\n",
    "    # Return the matches, join them if there are multiple matches\n",
    "    return \"\\n\\n---\\n\\n\".join(matches)\n",
    "\n",
    "\n",
    "# Call LLM to generate code\n",
    "def CoderLLM(user_question, code_context):\n",
    "\n",
    "    # Prompt for code generation\n",
    "    prompt_template = \"\"\"Write a python code based on the following Question and Context. You need to choose the correct sample codes from the Context to answer the Question.\n",
    "    1. Review the Question carefully and find all the 'Axis number', IO Inputs and Outputs, and add them to the first lines of the generated code in the following format: \n",
    "    # Axes = [Axis number 1, Axis number 2, ...]\n",
    "    # Inputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    # Outputs = [byte.bit 1, byte.bit 2, ...]\n",
    "    For instance, if the question is '...Axis 9..., ...Axis 12..., ...Axis 2..., Input 0.3 and 1.2, ...Output 3.4 and 6.1', then exact the information after matching the keywords: \"Axis\", \"Input\", \"Output\":\n",
    "    # Axes = [9, 12, 2]\n",
    "    # Inputs = [0.3, 1.2, ...]\n",
    "    # Outputs = [3.4, 6.1, ...]\n",
    "    2. Include all the generated codes within one paragraph between ```python and ``` tags. \n",
    "    3. Don't import any library.\n",
    "    4. Don't create any functions or example usage or unit test.\n",
    "    5. You need to wait until the Axes reaches the target position and stops, after the motion API, unless otherwise specified. For instance, Wmx3Lib_cm.motion.Wait(4), while 4 is the Axis specified in Axes.\n",
    "    6. Use StartPos for absolute positioning, as in 'Move Axis 4 to 200', and StartMov for relative positioning, as in 'Move Axis 4 by a distance of 200'.\n",
    "    7. Strictly follow the instruction for the specified profile type.\n",
    "    8. If acceleration/acc, deceleration/dec, and velocity/speed are not specified in the user query, use the default values provided in the context's sample codes.\n",
    "    ----------------------------------------------\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "\n",
    "    Context: \n",
    "    {context}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    prompt_code = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "    rag_chain = (\n",
    "        #{\"context\": context_msg, \"question\": RunnablePassthrough()}\n",
    "        prompt_code\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    " \n",
    "    codes = rag_chain.invoke({\"context\": code_context, \"question\": user_question})\n",
    "    \n",
    "    # Get python code from the output of LLM\n",
    "    codes = extract_code(codes)\n",
    "\n",
    "    return codes\n",
    "\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "# Corrects the provided error codes based on specified error information calling LLM\n",
    "def self_correct(err_codes):\n",
    "   # Search to get the python function as a context for self correction.\n",
    "    python_function_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3, \"filter\":{\"source\":\"./docs/WMX3API_FunctionPython.json\"}}) \n",
    "\n",
    "    # Split the string into lines\n",
    "    lines = err_codes.split('\\n')\n",
    "    error_str = ''\n",
    "    # Iterate through each line to find 'Error:'\n",
    "    for line in lines:\n",
    "        if 'Error:' in line:\n",
    "            # Assign the line containing 'Error:' to error_str\n",
    "            error_str = line\n",
    "    # error_str = 'GetInBit'\n",
    "    print('error string:----------------------\\n' + error_str )\n",
    "    python_function_result = python_function_retriever.invoke(error_str)\n",
    "    print(python_function_result)\n",
    "\n",
    "    err_codes = err_codes + \"\\n # Python function reference: ---------------- \\n \" + format_docs(python_function_result)\n",
    "    \n",
    "   # Remember to write \"python\" code in the prompt later\n",
    "    template = \"\"\"Correct the following codes based on the error infomation and function reference. \n",
    "    1. If the error is 'variable_name is not defined', try assigning it a value of None firstly.\n",
    "    2. If an error message indicates that acc, dec, velocity, or other arguments are out of range, assign them the default values presented in the preceding code samples.\n",
    "\n",
    "        {err_codes}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    code_corrected=rag_chain.invoke({\"err_codes\": err_codes})\n",
    " \n",
    "    return(code_corrected)\n",
    "\n",
    "\n",
    "# Decompose tasks from user questions using a LLM\n",
    "def task_decomposer_llm(user_question):\n",
    "   #  \n",
    "    template = \"\"\"Decompose the tasks based on the question, if it contains a numbered list formatted as '1. 2. 3. ...'. For example, the question 'Write Python code to execute the following tasks: 1. Move Axis 1 to 200; 2. Move Axis 9 a distance of 150; 3. Set IO output 4.3 to 1, and sleep for 1.5 seconds.' will be decomposed into three tasks as output adding 'Write python code to ':\n",
    "    1. Write python code to Move Axis 1 to 200;\n",
    "    2. Write python code to Move Axis 9 a distance of 150;\n",
    "    3. Write python code to Set IO output 4.3 to 1, and sleep for 1.5 seconds.\n",
    "\n",
    "    If there are not multiple tasks, just output the original question.\n",
    "        {questions}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    task_str=rag_chain.invoke({\"questions\": user_question})\n",
    "    pattern = re.compile(r'\\d+\\.\\s')\n",
    "    # Find all positions of task numbers\n",
    "    positions = [match.start() for match in pattern.finditer(task_str)]\n",
    "    tasks = []\n",
    "\n",
    "    # Loop through the positions to extract tasks\n",
    "    for i in range(len(positions)):\n",
    "        start = positions[i]\n",
    "        end = positions[i + 1] if i + 1 < len(positions) else len(task_str)\n",
    "        task = task_str[start:end].strip()\n",
    "        tasks.append(task)\n",
    "    \n",
    "    # If there are no multiple tasks, just output the original question.\n",
    "    if len(positions) == 0:\n",
    "        tasks.append(task_str)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "\n",
    "# Decompose tasks from user questions using a LLM\n",
    "def tasks_composer_llm(user_question, code_from_llm_str):\n",
    "   #  \n",
    "    template = \"\"\"Write a Python code that incorporates the Context_Codes (tasks) to address the following Question:\n",
    "\n",
    "    Question: \n",
    "    {question}\n",
    "\n",
    "    Context_Codes: \n",
    "    {context}\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "    \n",
    "    rag_chain = (\n",
    "            # {\"err_codes\": RunnablePassthrough()}\n",
    "            custom_rag_prompt\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    code_from_composer_llm=rag_chain.invoke({\"questions\": user_question, \"context\": code_from_llm_str})\n",
    "    # Get python code from the output of LLM\n",
    "    code_from_composer_llm = extract_code(code_from_composer_llm)\n",
    "    \n",
    "    return code_from_composer_llm\n",
    "\n",
    "\n",
    "# Send the code generated by the LLM to WMX3 engine\n",
    "def RunCode(codes_from_llm, task_info):\n",
    "\n",
    "    RunnableCode = make_code_runnable(codes_from_llm, llm_name, task_info)\n",
    "    # print(RunnableCode)\n",
    "\n",
    "    # Run Code in WMX3\n",
    "    codereturn = SendCode(RunnableCode)\n",
    "    # If there is an error, invoke llm to self-correct, and then send to WMX3 again.\n",
    "    if 'error' in codereturn.lower():\n",
    "        err_codes_0 = codereturn + '\\n # ------------------------------- \\n' + codes_from_llm\n",
    "        code_corrected = self_correct(err_codes_0)\n",
    "        msgCode = extract_code(code_corrected)\n",
    "        RunnableCode = make_code_runnable(msgCode, llm_name, task_info)\n",
    "        codereturn = SendCode(RunnableCode)\n",
    "        if 'error' in codereturn.lower():\n",
    "            self_correct_str = \"Self-correction but still got an error.\\n\\n\"\n",
    "        else:\n",
    "            self_correct_str = \"Self-corrected.\\n\\n\"\n",
    "        \n",
    "        codereturn += self_correct_str\n",
    "        print(self_correct_str)\n",
    "\n",
    "\n",
    "    return codereturn\n",
    "    \n",
    "\n",
    "\n",
    "# Evaluate dataset\n",
    "def EvalDataset():\n",
    "    # Define task range\n",
    "    task_infos = range(11, 21)\n",
    "\n",
    "    # Read JSON file\n",
    "    with open(\"./docs/WMX3API_MCEval_Evaluation_Dataset.json\", \"r\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    # Initialize statistics dictionary\n",
    "    statistics = {\n",
    "        1: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        2: {'correct': 0, 'syntax_error': 0, 'other_error': 0},\n",
    "        3: {'correct': 0, 'syntax_error': 0, 'other_error': 0}\n",
    "    }\n",
    "\n",
    "    total_correct = 0\n",
    "    total_syntax_error = 0\n",
    "    total_other_error = 0\n",
    "    total_self_corrected_error = 0\n",
    "\n",
    "    # Initialize error log list\n",
    "    error_log = []\n",
    "    self_corrected_log = []\n",
    "\n",
    "    # Iterate through task range\n",
    "    for task_info in tqdm(task_infos, desc=\"Processing tasks\"):\n",
    "        # Get task information\n",
    "        task_entry = next(item for item in dataset if item[\"TaskId\"] == task_info)\n",
    "        user_question = task_entry[\"Instruction\"]\n",
    "        difficulty = task_entry[\"Difficulty\"]\n",
    "        task_id = task_entry[\"TaskId\"]\n",
    "\n",
    "        # Call coder_router function\n",
    "        NoCoder, coder_router_result = coder_router(user_question)\n",
    "\n",
    "        # Route the result based on NoCoder value\n",
    "        if NoCoder == 0: # Coding task\n",
    "            tasks = task_decomposer_llm(user_question)\n",
    "            # Initialize a code string from LLM\n",
    "            code_from_llm_str = ''\n",
    "            for i in range(len(tasks)):\n",
    "                coder_return = coder_retrieval(coder_router_result)  # Code context\n",
    "                # Call CoderLLM function\n",
    "                code_from_llm = CoderLLM(user_question, coder_return)\n",
    "                code_from_llm_str += f'\\n#---------task{i}:---------\\n' + tasks[i] + f'\\n#---------code{i}:---------\\n' + code_from_llm \n",
    "\n",
    "        print(f\"Task ID: {task_id} 🔽\")\n",
    "        # Single task\n",
    "        if len(tasks) == 1:\n",
    "            # Run code\n",
    "            CoderResult = RunCode(code_from_llm, task_info)\n",
    "        else:  # Multi tasks\n",
    "            code_from_composer_llm = tasks_composer_llm(user_question, code_from_llm_str)\n",
    "            CoderResult = RunCode(code_from_composer_llm, task_info)\n",
    "\n",
    "        # Init Correctness, if equals 1, then plot.\n",
    "        Correctness = 0\n",
    "        # Check for \"Self-corrected\" in the result\n",
    "        if 'self-corrected' in CoderResult.lower():\n",
    "            self_corrected_log.append({'TaskId': task_info, 'Result': CoderResult})\n",
    "            if 'error' in CoderResult.lower():\n",
    "                error_info = {\n",
    "                    'TaskId': task_info,\n",
    "                    'Error': CoderResult\n",
    "                }\n",
    "                error_log.append(error_info)\n",
    "                \n",
    "                total_self_corrected_error += 1\n",
    "                if any(error in CoderResult.lower() for error in ('syntax error', 'NameError', 'AttributeError')):\n",
    "                    statistics[difficulty]['syntax_error'] += 1\n",
    "                    total_syntax_error += 1\n",
    "                else:\n",
    "                    statistics[difficulty]['other_error'] += 1\n",
    "                    total_other_error += 1\n",
    "            else:\n",
    "                statistics[difficulty]['correct'] += 1\n",
    "                total_correct += 1\n",
    "                Correctness = 1\n",
    "        else:\n",
    "            # Check if there is an error in the result\n",
    "            if 'error' in CoderResult.lower():\n",
    "                error_info = {\n",
    "                    'TaskId': task_info,\n",
    "                    'Error': CoderResult\n",
    "                }\n",
    "                error_log.append(error_info)\n",
    "\n",
    "                if any(error in CoderResult.lower() for error in ('syntax error', 'NameError', 'AttributeError')):\n",
    "                    statistics[difficulty]['syntax_error'] += 1\n",
    "                    total_syntax_error += 1\n",
    "                else:\n",
    "                    statistics[difficulty]['other_error'] += 1\n",
    "                    total_other_error += 1\n",
    "            else:\n",
    "                statistics[difficulty]['correct'] += 1\n",
    "                total_correct += 1\n",
    "                Correctness = 1\n",
    "\n",
    "        if Correctness == 1:\n",
    "            folder_path = f'/Users/yin/Documents/GitHub/MCCodeLog/{llm_name}'\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "            # Plot with the log file\n",
    "            log_file_path = os.path.join(folder_path, f\"{task_info}_{llm_name}_log.txt\")\n",
    "            plot_log(log_file_path)\n",
    "            print('# -------------------------------------------------------------------------\\n')\n",
    "\n",
    "    # Print overall statistics\n",
    "    total_tasks = total_correct + total_syntax_error + total_other_error\n",
    "    print(\"Overall Results:\")\n",
    "    print(f\"  Total Correct: {total_correct} ({total_correct / total_tasks:.2%})\")\n",
    "    print(f\"  Total Syntax Error: {total_syntax_error} ({total_syntax_error / total_tasks:.2%})\")\n",
    "    print(f\"  Total Other Error: {total_other_error} ({total_other_error / total_tasks:.2%})\")\n",
    "    print(f\"  Total Self-corrected Errors: {total_self_corrected_error}\")\n",
    "    print(\"\")\n",
    "\n",
    "    # Print statistics by difficulty\n",
    "    for difficulty, counts in statistics.items():\n",
    "        total_difficulty = counts['correct'] + counts['syntax_error'] + counts['other_error']\n",
    "        if total_difficulty != 0:\n",
    "            print(f\"Difficulty: {difficulty}\")\n",
    "            print(f\"  Correct: {counts['correct']} ({counts['correct'] / total_difficulty:.2%})\")\n",
    "            print(f\"  Syntax Error: {counts['syntax_error']} ({counts['syntax_error'] / total_difficulty:.2%})\")\n",
    "            print(f\"  Other Error: {counts['other_error']} ({counts['other_error'] / total_difficulty:.2%})\")\n",
    "            print(\"\")\n",
    "\n",
    "    # Print error log\n",
    "    if error_log:\n",
    "        print(\"Error Log:\")\n",
    "        for error in error_log:\n",
    "            print(f\"  TaskId: {error['TaskId']}, Error: {error['Error']}\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Print self-corrected log\n",
    "    if self_corrected_log:\n",
    "        print(\"Self-corrected Log:\")\n",
    "        for log in self_corrected_log:\n",
    "            print(f\"  TaskId: {log['TaskId']}, Result: {log['Result']}\")\n",
    "        print(\"\")\n",
    "\n",
    "# EvalDataset()\n",
    "\n",
    "self_correct('''codeerr:\n",
    "Traceback (most recent call last):\n",
    "  File \"\\\\mac\\Home\\Downloads\\codedemo\\sample.py\", line 258, in <module>\n",
    "    main()\n",
    "  File \"\\\\mac\\Home\\Downloads\\codedemo\\sample.py\", line 207, in main\n",
    "    ret = Wmx3Lib_Io.GetInputBit(0x0, 0x03, input_data)\n",
    "          ^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"\\\\mac\\Home\\Downloads\\codedemo\\WMX3ApiPython.py\", line 12445, in <lambda>\n",
    "    __getattr__ = lambda self, name: _swig_getattr(self, Io, name)\n",
    "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"\\\\mac\\Home\\Downloads\\codedemo\\WMX3ApiPython.py\", line 80, in _swig_getattr\n",
    "    raise AttributeError(\"'%s' object has no attribute '%s'\" % (class_type.__name__, name))\n",
    "AttributeError: 'Io' object has no attribute 'GetInputBit'. Did you mean: 'GetInBit'?\n",
    "!!!''')\n",
    "\n",
    "# self_correct('GetInBit')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-demo-IMu3vKF7-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
